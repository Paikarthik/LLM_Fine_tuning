# LLM Fine-Tuning  
This repository is about various methods for fine tuning or training a LLM from scratch.

## What is Fine-Tuning of LLM?
Fine-tuning refers to the process of adapting a pre-trained language model (LLM) to a specific task or domain. By leveraging a pre-trained model that has been trained on a large, general-purpose dataset, fine-tuning customizes the model to work more effectively for specialized tasks or domains.

## Why is Fine-Tuning Necessary?
LLMs are typically trained on large, publicly available datasets (e.g., data from the web), which may not always align with the specific knowledge required for a given application. Fine-tuning is necessary to provide the model with domain-specific knowledge, ensuring that it performs well in specialized areas such as medical, legal, or technical domains.

## Approaches for Domain Adaptation of LLMs:

### Prompt Engineering
Prompt engineering is the practice of designing precise and structured input prompts to help AI models produce more accurate and relevant responses. 

- **Auto-regressive Nature of LLMs**: LLMs are auto-regressive models, meaning that the output generated by the model is determined by the input, with each token influencing the next. The output is then fed back into the model as part of the input for subsequent generations.
  
- **Customizing Outputs**: By carefully curating the input prompts, you can influence and guide the model's output to meet specific requirements or produce responses in a desired format or style.

### Training the Model from Scrath  
We can train the model from scrath, if we have enough dataset about the domain along with the resources and budget.  

**Limitations**:  
  - Computationally expensive  
  - Financially expensive  
  - Creation of domain specific dataset is expensive if not available  
 
